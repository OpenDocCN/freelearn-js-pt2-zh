- en: Chapter 5. Asynchronous JavaScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Nowadays Internet users are impatient, a lag of 2-3 seconds during page loading
    or navigation and they lose their interest and will likely leave the service for
    something else. Our highest priority is to reduce user response time. The main
    approach here is known as *Cutting the mustard* ([http://www.creativebloq.com/web-design/responsive-web-design-tips-bbc-news-9134667](http://www.creativebloq.com/web-design/responsive-web-design-tips-bbc-news-9134667)).
    We extract the components of an application required for core experience and load
    them first. Then, progressively we add an enhanced experience. As for JavaScript,
    what we have to care the most about are nonblocking flows. Thus, we have to avoid
    loading scripts synchronously prior to HTML rendering, and we have to wrap all
    long-running tasks into asynchronous callbacks. This is something that you most
    probably already know. But do you do it efficiently?
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Nonblocking JavaScript
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Error-first callback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The continuation-passing style
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling asynchronous functions in the ES7 way
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parallel tasks and task series with the Async.js library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event handling optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nonblocking JavaScript
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First of all, let''s look at what really happens when we do things asynchronously.
    Whenever we invoke a function in JavaScript, it creates a new stack frame (execution
    object). Every inner call gets into this frame. Here the frames are pushed and
    popped from the top of the call stack in the **LIFO** (**last in, first out**)
    manner. In other words, in the code, we call the `foo` function and then the `bar`
    function; however, during execution, `foo` calls the `baz` function. In this case,
    in the `call` stack, we have the following sequence: `foo`, `baz`, and only then
    `bar`. So `bar` is called after the stack frame of `foo` is empty. If any of the
    functions perform a CPU-intensive task, all the successive calls wait for it to
    finish. However, JavaScript engines have **Event Queues** (or task queues).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Nonblocking JavaScript](img/00012.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: 'If we subscribe a function to a DOM event or pass a callback to a timer (`setTimeout`
    or `setInterval`) or through any Web I/O APIs (XHR, IndexedDB, and FileSystem),
    it ends up in a corresponding queue. Then, the browser''s event loop decides when
    and which callback to push in the callback stack. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `setTimeout( foo, 0 )`, we state that `foo` shall be called immediately,
    and then we call `bar`. However, `foo` lands in a queue and the event loop puts
    it deeper in the call stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This also means that if the `foo` callback performs a CPU-intensive task, it
    doesn''t block the main execution flow. Similarly, an asynchronously-made XHR/Fetch
    request doesn''t lock up the interaction while waiting for the server''s response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'How does this apply to real-world applications? Here is a common flow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The loading of JavaScript dependencies is queued, so the browser can render
    and deliver the UI to the user without waiting for that. As soon as the scripts
    are fully loaded, the application pushes two new tasks to the queue: *load news*
    and *authorize user*. Again, none of them blocks the main thread. Only when any
    of these requests complete and the main thread gets involved, it enhances the
    UI according to the newly received data. As soon as a user is authorized and the
    session token is retrieved, we can load user data. After the task is completed,
    we queue new ones.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, asynchronous code is harder to read compared to synchronous
    one. The execution sequences can be quite complex. Besides, we have to take extra
    care for error control. When going for synchronous code, we can wrap a block of
    the program with `try`/`catch` and intercept any errors thrown during execution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'However, if the call is queued, it slips out of the `try`/`catch` scope:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Yeah, asynchronous programming has its quirks. To get a grip on this, we will
    examine the existing practices of writing asynchronous code.
  prefs: []
  type: TYPE_NORMAL
- en: 'So to make the code asynchronous, we queue a task and subscribe for an event
    that is fired when the task is complete. Actually, we go for *Event-Driven Programming*,
    and in particular, we apply a *PubSub* pattern. For example, the `EventTarget`
    interface, which we touched upon in [Chapter 3](part0027_split_000.html#PNV62-f4ff6b81796e4f78aa983a623fb95daf
    "Chapter 3. DOM Scripting and AJAX"), *DOM Scripting and AJAX*, in a nutshell,
    is about subscribing listeners to events on DOM elements and firing these events
    either from UI or programmatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Behind the DOM, we use a similar principle, but implementations may differ.
    Probably the most popular interface is based on two main methods, `obj.on` (to
    subscribe a handler) and `obj.trigger` (to fire an event):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is how PubSub is implemented in abstraction frameworks, for example, Backbone.
    jQuery uses this interface on DOM events also. The interface gained its momentum
    through simplicity, but it doesn't really help with spaghetti code and doesn't
    cover error handling.
  prefs: []
  type: TYPE_NORMAL
- en: Error-first Callback
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The pattern used across all the asynchronous methods in Node.js is called **Error-first
    Callback**. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Any asynchronous method expects one of the arguments to be a callback. The full
    callback argument list depends on the caller method, but the first argument is
    always an error object or null. When we go for the asynchronous method, an exception
    thrown during function execution cannot be detected in a `try`/`catch` statement.
    The event happens after the JavaScript engine leaves the `try` block. In the preceding
    example, if any exception is thrown during the reading of the file, it lands on
    the callback function as the first and mandatory parameter. Regardless of its
    widespread use, this approach has its flaws. While writing real code with deep
    callback sequences, it is easy to run into a so-called **Callback Hell** ([http://callbackhell.com/](http://callbackhell.com/)).
    The code becomes pretty hard to follow.
  prefs: []
  type: TYPE_NORMAL
- en: Continuation-passing style
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We often need a chain of asynchronous calls, that is, a sequence of tasks where
    one task is started after another is completed. We are interested in an eventual
    result of asynchronous calls chain. In this case, we can benefit from **Continuation-passing
    style** (**CPS**). JavaScript has already a built-in `Promise` object. We use
    it to create a new `Promise` object. We put our asynchronous task in the `Promise`
    callback and invoke the `resolve` function of the argument list to notify the
    `Promise` callback that the task is resolved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, we called `foo`, that returns `Promise`. Using this
    method, we set a handler that invokes when `Promise` is fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: 'What about error control? When creating `Promise`, we can use the function
    given in the second argument (`reject`) to report a failure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The most exciting part about `Promises` is that they can be chained. We can
    pipe the callbacks to queue asynchronous tasks or transform values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Note that if we pass `0` to the `foo` function, the entry condition throws an
    exception and we will end up in a callback of the `catch` method. If an exception
    is thrown in one of the callbacks, it appears in the `catch` callback as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `Promise` chain is resolved in a manner similar to that of a waterfall model—the
    tasks are invoked one after another. We can also cause `Promise` to resolve after
    several parallel processing tasks are completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The `Promise.all` static method is not yet supported in all the latest browsers,
    but you can get this via a polyfill at [https://github.com/jakearchibald/es6-promise](https://github.com/jakearchibald/es6-promise).
  prefs: []
  type: TYPE_NORMAL
- en: 'Another probability is to cause `Promise` to resolve or reject whenever any
    of the concurrently running tasks are completed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Handling asynchronous functions in the ES7 way
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already have the Promise API in JavaScript. The upcoming technology is Async/Await
    API and is presented in a proposal ([https://tc39.github.io/ecmascript-asyncawait/](https://tc39.github.io/ecmascript-asyncawait/))
    for EcmaScript 7th edition. This describes how we can declare asynchronous functions
    that can halt without blocking anything and wait for the result of `Promise`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: At the moment, the API isn't supported in any browser; however, you can run
    it using the Babel.js transpiler on runtime. You can also fiddle with this example
    online at [http://codepen.io/dsheiko/pen/gaeqRO](http://codepen.io/dsheiko/pen/gaeqRO).
  prefs: []
  type: TYPE_NORMAL
- en: This new syntax allows us to write a code that runs asynchronously while appearing
    to be synchronous. Thus, we can use common constructions such as `try`/`catch`
    for asynchronous calls, which makes the code much more readable and easier to
    maintain.
  prefs: []
  type: TYPE_NORMAL
- en: Parallel tasks and task series with the Async.js library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another approach to deal with asynchronous calls is a library called **Async.js**
    ([https://github.com/caolan/async](https://github.com/caolan/async)). When using
    this library, we can explicitly specify how we want the batch of tasks to be resolved—as
    a waterfall (chain) or in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the first case, we can supply an array of callbacks to `async.waterfall`,
    assuming when one is completed, the next one is invoked. We can also pass the
    resolved value from one callback to another and receive the aggregate value or
    the thrown exception in a method''s `on-done` callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, we pass an array of callbacks to `async.parallel`. This time, all
    of them run in parallel, but when all are resolved, we receive the results or
    the thrown exception in the method''s `on-done` callback:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Surely, we can combine the flows. Besides, the library provides iteration methods,
    such as `map`, `filter`, and `each`, that applies to the array of asynchronous
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Async.js was the first project of this kind. Today, there are many libraries
    inspired by this. If you want a lightweight and robust solution similar to Async.js,
    I would recommend that you check Contra ([https://github.com/bevacqua/contra](https://github.com/bevacqua/contra)).
  prefs: []
  type: TYPE_NORMAL
- en: Event handling optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It must have happened to you while writing a form inline validator that you
    run into a problem. As you type it, the `user-agent` keeps sending validation
    requests to the server. This way you might quickly pollute the network with spawning
    XHRs. Another sort of problem that you may be familiar with, is that some UI events
    ( `touchmove`, `mousemove`, `scroll`, and `resize` ) are fired intensively and
    subscribed handlers may overload the main thread. These problems can be solved
    using one of two approaches known as *debouncing* and *throttling*. Both functions
    are available in third-party libraries such as Underscore and Lodash (`_.debounce`
    and `_.throttle`). However, they can be implemented with a little `o` code and
    one doesn't need to depend on extra libraries for this functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Debouncing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By debouncing, we ensure that a handler function is called once for a repeatedly
    emitted event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s say we want a widget to lazy load only when it comes into view, which
    in our case requires a user to scroll the page at least by 200 pixels downwards:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If we simply subscribe a listener to the scroll event, it will be called quite
    a number of times between the time interval when the user starts and stops scrolling.
    Thanks to the debounce proxy, the handler that checks whether it's the time to
    load the widget or not is called only once, when the user stops scrolling.
  prefs: []
  type: TYPE_NORMAL
- en: Throttling
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By throttling, we set how often the handler is allowed to be called while the
    event is fired:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'So if we subscribe a handler to the `mousemove` event on a container via throttle,
    the `handler` function once a time (second here) until the mouse cursors leaves
    the container boundaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Writing callbacks that don't impact latency-critical events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some of the tasks that we have do not belong to a core functionality and may
    run in the background. For example, we want to dispatch analytics data while scrolling.
    We do this without debouncing or throttling that would overload the UI thread
    and would likely make the app unresponsive. Debouncing isn't relevant here and
    throttling won't give precise data. However, we can use the `requestIdleCallback`
    native method ([https://w3c.github.io/requestidlecallback/](https://w3c.github.io/requestidlecallback/))
    to schedule the task at the time when `user-agent` is idle.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of our most prioritized goals is to reduce user-response time, that is,
    the application architecture must ensure the user flow is never blocked. This
    can be achieved by queuing any long-running tasks for asynchronous invocation.
    However, if you have a number of asynchronous calls among which some are intended
    to run in parallel and some sequentially, without taking special care, it's easy
    to run into a so-called Callback Hell. A proper use of such approaches as *Continuation-passing
    style* (*Promise API*), the Async/Await API, or an external library such as Async.js
    may significantly improve your asynchronous code. We also have to remember that
    some events such as `scroll`/`touch`/`mousemove`, while being intensively fired,
    may cause unnecessary CPU load by calling subscribed listeners frequently. We
    can avoid these problems using debouncing and throttling techniques.
  prefs: []
  type: TYPE_NORMAL
- en: By learning the basis of asynchronous programming, we can write nonblocking
    applications. In [Chapter 6](part0042_split_000.html#181NK2-f4ff6b81796e4f78aa983a623fb95daf
    "Chapter 6. A Large-Scale JavaScript Application Architecture"), *A Large-Scale
    JavaScript Application Architecture*, we will talk about how to make our applications
    scalable and improve the maintainability in general.
  prefs: []
  type: TYPE_NORMAL
